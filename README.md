# Sentiment Analysis Pipeline

Ten projekt zawiera kompletny pipeline eksperymentÃ³w z uÅ¼yciem `DVC`, `Docker` i `wandb`. Instrukcja poniÅ¼ej pozwoli Ci zbudowaÄ‡ Å›rodowisko i zreprodukowaÄ‡ wyniki.

---

## ğŸ³ Uruchomienie przez Dockera

### 1. Zbuduj obraz Dockera

```bash
make build
```

### 2. StwÃ³rz plik .env z kluczem API do Weights & Biases

WANDB_API_KEY=twoj_klucz_api

### 3. Pobierz dane i rozmieÅ›Ä‡ je w katalogach
ğŸ—‚ï¸ rt-polarity

- Pobierz dane z: http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz

- Wypakuj zawartoÅ›Ä‡ do:
```bash
data/raw_data/rt-polarity/
```

- Tak aby w Å›rodku byÅ‚y pliki:
```
rt-polarity.neg
rt-polarity.pos
```

ğŸ—‚ï¸ sephora
- Pobierz dane z: https://www.kaggle.com/datasets/nadyinky/sephora-products-and-skincare-reviews

- Wypakuj wszystkie pliki .csv do:

```bash
data/raw_data/sephora
```
- Przez robienie projektu na custom dataset naleÅ¼y zmieniÄ‡ nazwÄ™ kolumny "rating" z Reviews data na "LABEL-rating"

### 4. Uruchom kontener Dockera z dostÄ™pem do Å›rodowiska
```bash
make run_docker
```

### 5. WewnÄ…trz kontenera wykonaj pipeline
```bash
dvc repro
```

### ğŸ“ Struktura konfiguracji

strukturÄ™ folderÃ³w naleÅ¼y odwzorowaÄ‡ w przypadku brakÃ³w

- `params.yaml` â€” gÅ‚Ã³wny plik parametrÃ³w, wspÃ³Å‚dzielony miÄ™dzy wszystkimi konfiguracjami. Zawiera ustawienia modelu, cech i ogÃ³lne hiperparametry.
- `configs/sephora.yaml`, `configs/rt-polarity.yaml` â€” konfiguracje specyficzne dla danego zbioru danych (Å›cieÅ¼ki, kolumny, parametry pipelineâ€™u).
- `data/raw_data/` â€” katalog, do ktÃ³rego naleÅ¼y rÄ™cznie wrzuciÄ‡ nieprzetworzone dane wejÅ›ciowe:
  - `sephora/` z plikami CSV z Kaggle
  - `rt-polarity/` z plikami `rt-polarity.neg` i `rt-polarity.pos`
- `data/processed_data/` â€” dane wczytane z raw_data, przetworzone na pkl, gotowe do analizy i preprocesingu.
- `data/preprocessed_data/` â€” dane po wstÄ™pnym przetworzeniu.
- `data/train_test_split/` â€” pliki zawierajÄ…ce podziaÅ‚y na zbiÃ³r treningowy i testowy.
- `data/models/` â€” zapisane modele dla kaÅ¼dej konfiguracji wraz z najlepszymi parametrami w plikach .json.
- `data/metrics/` â€” metryki ewaluacyjne zapisane dla kaÅ¼dego eksperymentu.
- `data/notebooks/` â€” dane generowane podczas eksploracji w notatnikach.
- `notebooks/` â€” eksploracja danych, analizy EDA, szukanie hiperparametrÃ³w oraz analiza sharp.
- `excercises/` â€” katalog na Ä‡wiczenia/testy.
- `results/` â€” koÅ„cowe tabele wynikÃ³w porÃ³wnujÄ…cych modele/datysety.
- `raports/` â€” wykresy, tabele lub inne artefakty koÅ„cowe do raportu.
- `scripts/` â€” pomocnicze skrypty (np. do pobierania, czyszczenia danych).
- `src/` â€” gÅ‚Ã³wny kod projektu (transformery, funkcje narzÄ™dziowe, pipeline).

### ğŸ“ Uwagi
Pipeline automatycznie wykonuje caÅ‚oÅ›Ä‡ przetwarzania i zapisuje wyniki bez potrzeby dodatkowych komend.

Wymagane jest posiadanie konta w Weights & Biases i ustawienie wÅ‚asnego klucza API w .env.

### âœ… Efekt koÅ„cowy
Po wykonaniu dvc repro:

- Modele zostanÄ… zapisane w models/{dataset_name}

- Wyniki zostanÄ… zapisane w results/test_results.md

- SzczegÃ³Å‚owe metryki w data/metrics/*
