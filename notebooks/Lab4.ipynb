{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizy eksploracyjna (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import nltk\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from src.utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"data/processed_data/dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza typów danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane kategoryczne oraz numeryczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath_cols = [\n",
    "    \"limited_edition\",\n",
    "    \"new\",\n",
    "    \"online_only\",\n",
    "    \"out_of_stock\",\n",
    "    \"sephora_exclusive\",\n",
    "    \"contains_refund\",\n",
    "]\n",
    "num_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns.values\n",
    "num_cols = [col for col in num_cols if col not in cath_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ile znajduje się w zbiorze cech kategorycznych, a ile numerycznych?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cech kategorycznych: 6\n",
    "\n",
    "Cech numerycznych: 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cech kategorycznych: {len(cath_cols)}\")\n",
    "print(f\"Cech numerycznych: {len(num_cols)}\")\n",
    "\n",
    "print(f\"Kategoryczne: {cath_cols}\")\n",
    "print(f\"Numeryczne: {num_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **czy zmienna wyjściowa jest kategoryczna, czy numeryczna?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienna wyjściowa jest w formacie float64 co sugeruje numeryczność, tym bardziej iż 1 jest faktycznie najniższą wartością, a 5 najwyższą.\n",
    "\n",
    "Jednoczenie zawiera wartości kolejno 1, 2, 3, 4, 5 i podczas grupowania możemy sprawdzać cechy dla danego ratingu.\n",
    "\n",
    "Wniosek: cecha jest głównie numeryczna, lecz może zostać potraktowana jako kategoryczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Zmienna wyjściowa posiada wartości: {df['LABEL-rating'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **czy i ile w zbiorze jest brakujących wartości? Dla jakich zmiennych? Co z tego wynika? Jakie są możliwe sposoby radzenia sobie z brakującymi wartościami?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zbiorze występują brakujące wartości.\n",
    "\n",
    "Brakuje 3990364 wartości.\n",
    "\n",
    "Brakuje wartości dla zmiennych helpfulness, value_price_usd, sale_price_usd, child_max_price, child_min_price.\n",
    "\n",
    "Wynika z tego, iż możemy mieć trudność z wnioskowaniem na podstawie tych kolumn, lecz kolmunę *helpfulness* możemy obliczyć manualnie ze wzoru helpfulness = total_pos_feedback_count / total_feedback_count.\n",
    "\n",
    "Występuje kilka sposobów poradzenia sboie z brakującymi wartościami takie jak:\n",
    "- Manualne uzupełnianie danych\n",
    "- Zebranie dodatkowych danych w celu uzupełnienia braków\n",
    "- Uzupełnienie wartością domyślną\n",
    "- Zignorowanie braków\n",
    "- Uzupełnienie danych wartościami mediany bądź sumy\n",
    "- Uzupełnienie danych na podstawie pewnych algorytmów jak k-najbliższych sąsiadów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"W zbiorze {'' if df.isnull().values.any() else 'nie'}występują brakujące wartości.\"\n",
    ")\n",
    "print(\n",
    "    f\"W zbiorze występuje {df[cath_cols + num_cols].isnull().sum().sum()} brakujących wartości.\"\n",
    ")\n",
    "df[cath_cols + num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- czy któreś z cech są skorelowane? Co z tego może wynikać?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wysoko bądź średnio skorelowane są:\n",
    "\n",
    "#### użyteczne\n",
    "- reviews, loves_count - posiada wysoką korelacje, sugerując iż wiele opinii posiada wiele serduszek\n",
    "- value_price_usd, rating - jest negatywnie skorelowane sugerując, iż dla wysokich cen jest niski rating\n",
    "- child_count, reviews -  posiada średnią korelację, im więcej produktów podobnych tym więcej opinii\n",
    "- sale_price_usd, rating - im większa przecena tym wyższy rating\n",
    "#### bezużyteczne korelacje\n",
    "- total_neg_feedback_count, total_pos_feedback_count, total_feedback_count - spowodowane tym, iż total wynika z dwóch pozostałych.\n",
    "- value_price_usd, price_usd, sale_price_usd - wartości są bardzo podobne, ponieważ jedna wynika z drugiej.\n",
    "- child_max_price, child_min_price, price_usd - ponownie wartości są stosunkowo podobne, ponieważ odpisują ten sam produkt\n",
    "\n",
    "Niewiele zmienych posiada wysoką i średnią korelację.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Numerical Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która? Czy któraś nie koreluje?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koreluje: rating, expclamation_count, helpfulness, total_neg_feedback_count oraz sale_price_usd.\n",
    "\n",
    "Nie koreluje: new, reviews, online_only, child_max_price, child_count, out_of_sstock, sephora_exclusive, price_usd, review_lengst, loves_count, limited_edition, child_min_price, unique_word_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df[cath_cols + num_cols].corr().abs()\n",
    "correlation_label = correlation[\"LABEL-rating\"].drop(\"LABEL-rating\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation_label.sort_values(ascending=False).plot(kind=\"bar\")\n",
    "plt.title(\"Correlation with rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane tekstowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = df.select_dtypes(include=[\"object\"]).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- czy któreś ze słów wydają się dominować w zbiorze?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominującymi słowami są \"skin\", \"product\", \"love\", \"use\", \"like\", \"face\", \"using\", \"really\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", str(text))\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "df[\"cleaned_text\"] = df[\"review_text\"].apply(clean_text)\n",
    "df[\"cleaned_text_tokens\"] = df[\"cleaned_text\"].apply(lambda x: [word for word in x.split() if word not in stop_words])\n",
    "all_words = [word for tokens in df[\"cleaned_text_tokens\"] for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(all_words)\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=[\"word\", \"count\"]).sort_values(\n",
    "    by=\"count\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(word_freq_df[\"word\"][0:25], word_freq_df[\"count\"][0:25])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Word frequency\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- czy najpopularniejsze słowa różnią się znacząco pomiędzy klasami? Czy potrafisz wyróżnić słowa mogące wpływać w znaczym stopniu na sentyment?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpopularniejsze słowa nieznacznie różnią się pomiędzy klasami.\n",
    "\n",
    "3 pierwsze wyrazy dla rating 1-4 to \"skin\", 'product' oraz 'like'.\n",
    "\n",
    "Dla ratingu 5 to \"skin\", 'product' oraz 'love'.\n",
    "\n",
    "Charakterystycznymi wyrazami dla klasy 1 oraz 2 są: **get**, **didn't**, **don't**, **even**, **tried**, **made**\n",
    "\n",
    "Dla klasy 3 są **think**, **nice**\n",
    "\n",
    "Dla klasy 4 oraz 5 są **great**, **amazing**, **moisturizer**, **cream**, **makeup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    filtered_df = df[df[\"LABEL-rating\"] == i]\n",
    "    all_words = [word for tokens in filtered_df[\"cleaned_text_tokens\"] for word in tokens]\n",
    "    word_counts = Counter(all_words)\n",
    "    word_freq_df = pd.DataFrame(\n",
    "        word_counts.items(), columns=[\"word\", \"count\"]\n",
    "    ).sort_values(by=\"count\", ascending=False)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(word_freq_df[\"word\"][0:15], word_freq_df[\"count\"][0:15])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"Word frequency for rating {i}\")\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodatkowe pytania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- jaka jest charakterystyka tekstu (np. długość, czystość)? (opisane w dodatkowych pytaniach)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zazwyczaj recenzje posiadają 320 znaków, ponad 5 zdań, 45 unikatowych wyrazów oraz 0.7 wykrzyknika.\n",
    "\n",
    "Największą różnice można odnotować w liczbie wykrzykników dla reviews o ocenie 5, gdzie wartośc wynosi 1.2 wykrzyknika na ocenę, im niższa ocena tym mniej wykrzykników.\n",
    "\n",
    "Statystycznie im więcej zdań tym lepsza ocena.\n",
    "\n",
    "w kwestii unikatowych wyrazów oraz długości recenzji dla rating 1-4 im więcej wyrazów i im dłuższa recenzja tym wyższy rating, lecz zależnośc nie jest prawdziwa dla rating = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    filtered_df = df[df[\"LABEL-rating\"] == i]\n",
    "\n",
    "    text_data.append(\n",
    "        {\n",
    "            \"avg length\": filtered_df[\"review_length\"].mean(),\n",
    "            \"avg sentence count\": filtered_df[\"review_text\"]\n",
    "            .str.split(r\"[.!?]\")\n",
    "            .str.len()\n",
    "            .mean(),\n",
    "            \"avg unique word count\": filtered_df[\"unique_word_count\"].mean(),\n",
    "            \"avg exclamation count\": filtered_df[\"exclamation_count\"].mean(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"avg length\",\n",
    "    \"avg sentence count\",\n",
    "    \"avg unique word count\",\n",
    "    \"avg exclamation count\",\n",
    "]\n",
    "ratings = [1, 2, 3, 4, 5]\n",
    "colors = [\"skyblue\", \"lightcoral\", \"lightgreen\", \"gold\"]\n",
    "\n",
    "values = {category: [entry[category] for entry in text_data] for category in categories}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, category, color in zip(axes.flatten(), categories, colors):\n",
    "    bars = ax.bar(\n",
    "        ratings, values[category], color=color, edgecolor=\"black\", label=category\n",
    "    )\n",
    "\n",
    "    ax.set_title(category)\n",
    "    ax.set_xlabel(\"Rating\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.set_xticks(ratings)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Czy rozkład klas w zmiennej wyjściowej (LABEL-rating) jest zrównoważony?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istnieje nierównomierny rozkład klas - klasa 5 posiada prawie 700_000 reprezentantów, gdzie klasy 1 oraz 2 posiadają po 50_000 reprezentatnów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LABEL-rating\"].value_counts().sort_index().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Czy są duplikaty w zbiorze danych?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak, istanieje 925 duplikatów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciekawe spostrzeżenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zaobserwowano, iż niektóre kolumny mają nieprawidłowy typ object zamiast int64. Zdecydowano się naprawić typy w skrycpie process_data.py\n",
    "2. Zaobserwowano wiele brakujących wartości, może warto je uzupełnić bądź usunąć rekordy z brakującymi wartościami\n",
    "3. Wykrzykniki fenomentalnie określają czy opinia będzie miała wysoką ocenę\n",
    "4. Najczęstsze wyrazy  dla poszczególnych ratingów są bardzo intuicyjne. Niskie wartości - didin't, don't. Średnie wartości - like. Wysokie wartości - love, amazing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rekomendowane dalsze kroki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Warto dodać metrykę liczącą wykrzykniki w wypowiedzi.\n",
    "- Warto poprawić typ danych dla odpowiednich kolumn\n",
    "- Warto uzupełnić brakujące wartości\n",
    "- Warto zastanowić się nad zwiększeniem liczebności klas o niskim ratingu\n",
    "- Warto usunąć duplikaty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
